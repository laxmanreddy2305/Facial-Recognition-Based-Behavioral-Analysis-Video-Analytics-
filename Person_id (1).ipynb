{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMg0ZR8YsCwiq0cEbAytos0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip uninstall -y moviepy fer facenet-pytorch -q\n","!pip install moviepy==1.0.1 fer==22.4.0 decord==0.6.0 facenet-pytorch==2.5.3 transformers==4.42.3 torch torchvision torchaudio tqdm pandas --quiet"],"metadata":{"id":"rBULVSqnq8U_","executionInfo":{"status":"ok","timestamp":1761590864025,"user_tz":240,"elapsed":8688,"user":{"displayName":"Laxman Reddy","userId":"11042157393697719950"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["import torch, cv2, numpy as np, pandas as pd, os\n","from tqdm import tqdm\n","from fer import FER\n","from facenet_pytorch import MTCNN, InceptionResnetV1\n","from transformers import XCLIPProcessor, XCLIPModel\n","from decord import VideoReader, cpu\n","from google.colab import files\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","print(\"üîπ Loading models ...\")\n","face_detector = MTCNN(keep_all=True, device=device)\n","facenet = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n","emotion_detector = FER(mtcnn=True)\n","action_processor = XCLIPProcessor.from_pretrained(\"microsoft/xclip-base-patch32\")\n","action_model = XCLIPModel.from_pretrained(\"microsoft/xclip-base-patch32\").to(device)\n","print(\"‚úÖ All models loaded successfully!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"id":"sIfJYhzsrA_H","executionInfo":{"status":"error","timestamp":1761590868904,"user_tz":240,"elapsed":30,"user":{"displayName":"Laxman Reddy","userId":"11042157393697719950"}},"outputId":"09bb3113-e7bd-4340-ad71-08499b80ae86"},"execution_count":7,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2495275276.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfacenet_pytorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMTCNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInceptionResnetV1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXCLIPProcessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXCLIPModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m     ) from _err\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m from pandas._config import (\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mget_option\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mset_option\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/_config/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;34m\"warn_copy_on_write\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m ]\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdates\u001b[0m  \u001b[0;31m# pyright: ignore[reportUnusedImport]  # noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m from pandas._config.config import (\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/_config/config.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m from pandas._typing import (\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/_typing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBitGenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mpublic_symbols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'testing'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         public_symbols -= {\n\u001b[1;32m    339\u001b[0m             \u001b[0;34m\"core\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"matrixlib\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/random/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;31m# add these for module-freeze analysis (like PyInstaller)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_common\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_bounded_integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/random/_pickle.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmtrand\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_philox\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPhilox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_pcg64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCG64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPCG64DXSM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_sfc64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSFC64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mnumpy/random/mtrand.pyx\u001b[0m in \u001b[0;36minit numpy.random.mtrand\u001b[0;34m()\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"]}]},{"cell_type":"code","source":["print(\"üì§ Please upload one or more .mp4 videos...\")\n","uploaded = files.upload()\n","\n","video_dir = \"videos\"\n","os.makedirs(video_dir, exist_ok=True)\n","for name, data in uploaded.items():\n","    with open(os.path.join(video_dir, name), \"wb\") as f:\n","        f.write(data)\n","\n","print(f\"‚úÖ Uploaded {len(uploaded)} videos to '{video_dir}'\")\n"],"metadata":{"id":"qAYBwOgkrQA4","executionInfo":{"status":"aborted","timestamp":1761590754825,"user_tz":240,"elapsed":2,"user":{"displayName":"Laxman Reddy","userId":"11042157393697719950"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_face_embeddings(frame):\n","    boxes, _ = face_detector.detect(frame)\n","    faces = []\n","    embeddings = []\n","    if boxes is not None:\n","        for box in boxes:\n","            x1, y1, x2, y2 = [int(b) for b in box]\n","            face = frame[y1:y2, x1:x2]\n","            if face.size == 0:\n","                continue\n","            face_resized = cv2.resize(face, (160, 160))\n","            face_rgb = cv2.cvtColor(face_resized, cv2.COLOR_BGR2RGB)\n","            face_tensor = torch.tensor(face_rgb / 255.0).permute(2, 0, 1).unsqueeze(0).float().to(device)\n","            with torch.no_grad():\n","                emb = facenet(face_tensor).cpu().numpy().flatten()\n","            faces.append(face)\n","            embeddings.append(emb)\n","    return faces, embeddings\n","\n","\n","def get_top_actions(video_path, top_k=3):\n","    try:\n","        actions = [\"a person dancing\", \"a person speaking\", \"a person sitting\", \"a person walking\", \"a person smiling\"]\n","        inputs = action_processor(text=actions, videos=video_path, return_tensors=\"pt\").to(device)\n","        with torch.no_grad():\n","            logits = action_model(**inputs).logits_per_video.softmax(dim=1)[0].cpu().numpy()\n","        top_idx = logits.argsort()[-top_k:][::-1]\n","        return [f\"{actions[i]}:{logits[i]:.2f}\" for i in top_idx]\n","    except Exception as e:\n","        return [f\"‚ö†Ô∏è Action error: {str(e)}\"]\n","\n","\n","def get_emotion(frame):\n","    try:\n","        result = emotion_detector.detect_emotions(frame)\n","        if not result: return \"No face\"\n","        emotions = result[0]['emotions']\n","        sorted_emo = sorted(emotions.items(), key=lambda x: x[1], reverse=True)\n","        top3 = [f\"{e}:{v:.2f}\" for e, v in sorted_emo[:3]]\n","        return \", \".join(top3)\n","    except:\n","        return \"Error\"\n"],"metadata":{"id":"R4xYdCQUrZSi","executionInfo":{"status":"aborted","timestamp":1761590754828,"user_tz":240,"elapsed":3,"user":{"displayName":"Laxman Reddy","userId":"11042157393697719950"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.cluster import AgglomerativeClustering\n","\n","all_faces = []\n","all_embeddings = []\n","all_records = []\n","\n","for video_name in os.listdir(video_dir):\n","    if not video_name.endswith(\".mp4\"): continue\n","    path = os.path.join(video_dir, video_name)\n","    vr = VideoReader(path, ctx=cpu(0))\n","    frame_count = len(vr)\n","    fps = vr.get_avg_fps()\n","    chunk_size = int(fps * 5)\n","    print(f\"‚ñ∂Ô∏è Processing {video_name}: {frame_count} frames\")\n","\n","    for i in tqdm(range(0, frame_count, chunk_size)):\n","        frame = vr[i].asnumpy()\n","        faces, embeds = get_face_embeddings(frame)\n","        emo = get_emotion(frame)\n","        temp_video = f\"/tmp/clip_{video_name}_{i}.mp4\"\n","\n","        # Create short clip for action recognition\n","        out = cv2.VideoWriter(temp_video, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame.shape[1], frame.shape[0]))\n","        for _ in range(int(fps)):\n","            out.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n","        out.release()\n","        actions = get_top_actions(temp_video)\n","\n","        for face, emb in zip(faces, embeds):\n","            face_id = f\"{video_name}_f{i}\"\n","            face_path = f\"/tmp/{face_id}.jpg\"\n","            cv2.imwrite(face_path, cv2.cvtColor(face, cv2.COLOR_RGB2BGR))\n","            all_faces.append(face_path)\n","            all_embeddings.append(emb)\n","            all_records.append({\n","                \"Video\": video_name,\n","                \"Frame\": i,\n","                \"Actions\": \", \".join(actions),\n","                \"Emotions\": emo,\n","                \"FacePath\": face_path\n","            })\n","\n","print(\"‚úÖ All faces, actions & emotions extracted!\")\n","\n","# Cluster faces\n","if len(all_embeddings) > 1:\n","    cluster = AgglomerativeClustering(n_clusters=None, metric=\"euclidean\", linkage=\"ward\", distance_threshold=1.0)\n","    labels = cluster.fit_predict(np.array(all_embeddings))\n","else:\n","    labels = np.zeros(len(all_embeddings))\n","\n","for i, rec in enumerate(all_records):\n","    rec[\"PersonID\"] = int(labels[i])\n","\n","df = pd.DataFrame(all_records)\n","print(f\"\\n‚úÖ Processed {len(df)} faces, {len(set(labels))} unique persons detected.\")\n","df.head()\n"],"metadata":{"id":"3Q-QBrMDrcaJ","executionInfo":{"status":"aborted","timestamp":1761590754833,"user_tz":240,"elapsed":2,"user":{"displayName":"Laxman Reddy","userId":"11042157393697719950"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from IPython.display import Image, display\n","\n","print(f\"Total faces: {len(df)}, Unique persons: {df['PersonID'].nunique()}\\n\")\n","for pid in sorted(df['PersonID'].unique()):\n","    print(f\"üßç Person {pid}\")\n","    sample_faces = df[df[\"PersonID\"] == pid][\"FacePath\"].head(3)\n","    for path in sample_faces:\n","        display(Image(path))\n","    print()\n"],"metadata":{"id":"7AMn5hh5r2Xd","executionInfo":{"status":"aborted","timestamp":1761590754857,"user_tz":240,"elapsed":22,"user":{"displayName":"Laxman Reddy","userId":"11042157393697719950"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["person_id = int(input(\"Enter Person ID to view details: \"))\n","person_df = df[df[\"PersonID\"] == person_id]\n","\n","if person_df.empty:\n","    print(\"‚ùå No such person found.\")\n","else:\n","    print(f\"\\nüé¨ Person {person_id} appeared in {person_df['Video'].nunique()} videos.\")\n","    display(person_df[[\"Video\", \"Frame\", \"Actions\", \"Emotions\"]])\n","\n","    print(\"\\nüñºÔ∏è Sample Faces:\")\n","    for img in person_df[\"FacePath\"].head(5):\n","        display(Image(img))\n"],"metadata":{"id":"fp80c0XRr-gS","executionInfo":{"status":"aborted","timestamp":1761590754861,"user_tz":240,"elapsed":6,"user":{"displayName":"Laxman Reddy","userId":"11042157393697719950"}}},"execution_count":null,"outputs":[]}]}